# ğŸ§¾ Customer Churn Prediction

An endâ€‘toâ€‘end **machine learning** project to predict **customer churn** for subscription/contractâ€‘based businesses.  
This repository includes data preprocessing, feature engineering, model training (Logistic Regression, Random Forest, XGBoost), **threshold tuning** for business goals, and rigorous evaluation (ROCâ€‘AUC, PRâ€‘AUC, F1).

---

## ğŸ“– Overview
Churn prediction helps allocate retention efforts efficiently (discounts, outreach, winâ€‘back campaigns).  
This project builds a reproducible pipeline and compares multiple models, focusing on **recall** for early churn capture while controlling precision via **threshold selection**.

**Highlights**
- Clean pipelines with `ColumnTransformer` + `Pipeline` (no leakage)  
- Robust evaluation on **stratified** train/test split + optional crossâ€‘validation  
- **Calibration** for reliable probabilities (isotonic)  
- Costâ€‘aware thresholding (maximize **F2** or Youdenâ€‘J)  
- Feature importance (modelâ€‘specific and **SHAP** optional)

---

## ğŸ—‚ï¸ Dataset
- **Target**: `churn` (1 = churned, 0 = retained)  
- **Typical features**: demographics, contract type, tenure, monthly charges, payment method, product usage (sessions, tickets, failures), engagement scores.  
- Example CSVs:
```
data/
â”œâ”€ train.csv
â””â”€ test.csv
```
> Replace with your own data; ensure consistent column names between train/test.

---

## ğŸ”§ Preprocessing & Feature Engineering
- Missing value imputation (numeric/ categorical)  
- Scaling numerical features (**fit on train only**)  
- Oneâ€‘hot encoding for categoricals (ignore unknowns at inference)  
- Domain features (e.g., ARPU, tenure buckets, complaints in last 30d)  
- Optional: interaction terms and targetâ€‘encoding (with CV to avoid leakage)

---

## ğŸ§  Models
- **Logistic Regression** (baseline + interpretability)  
- **Random Forest** (nonâ€‘linear baseline)  
- **XGBoost** (strong tabular learner)  
- *(Optional)* LightGBM, CatBoost

---

## ğŸ“ˆ Evaluation
Primary metrics:
- **ROCâ€‘AUC** â€” ranking ability
- **PRâ€‘AUC** â€” useful under class imbalance
- **F1 / F2** â€” balance or recallâ€‘heavy scenarios
- **Confusion matrix** at chosen threshold

**Threshold selection**:
- Sweep thresholds to maximize **F2** (recallâ€‘oriented) or **Youdenâ€‘J**  
- Choose operating point aligned with business cost matrix

---

## ğŸ§© Repository Structure (suggested)
```
Customer-Churn-Prediction/
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_eda.ipynb
â”‚  â”œâ”€ 02_training_baselines.ipynb
â”‚  â”œâ”€ 03_threshold_calibration.ipynb
â”œâ”€ src/
â”‚  â”œâ”€ data.py          # load/split; stratification; leakage-safe transforms
â”‚  â”œâ”€ features.py      # preprocessors, domain features
â”‚  â”œâ”€ models.py        # model builders (logreg/RF/XGB)
â”‚  â”œâ”€ train.py         # fit + CV
â”‚  â”œâ”€ eval.py          # metrics, curves, threshold sweep
â”‚  â”œâ”€ explain.py       # SHAP (optional)
â”œâ”€ reports/figures/    # ROC/PR curves, CM, feature importance
â”œâ”€ data/               # (gitignored)
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âš™ï¸ Setup & Usage
1) **Clone & install**
```bash
git clone https://github.com/ziaee-mohammad/Customer-Churn-Prediction.git
cd Customer-Churn-Prediction
pip install -r requirements.txt
```

2) **Run notebooks** (EDA â†’ training â†’ threshold)
```bash
jupyter notebook
```

3) **Or use scripts (if added)**
```bash
python -m src.train --model xgboost
python -m src.eval  --threshold auto_f2
```

---

## ğŸ“¦ Requirements (example)
```
pandas
numpy
scikit-learn
xgboost
matplotlib
seaborn
shap           # optional
```

---

## âœ… Reproducibility & Antiâ€‘Leakage Checklist
- Use **stratified** splits; fix random seeds (NumPy/sklearn)  
- Keep scaling/encoding **inside** the pipeline; `fit` on train only  
- Report ROC/PR curves; store chosen threshold and rationale  
- Calibrate probabilities if needed (`CalibratedClassifierCV`)  
- Log data windows used (train/val/test) for temporal stability

---

## ğŸ“ˆ Example Results (replace with your numbers)
| Model | ROCâ€‘AUC | PRâ€‘AUC | F1 | F2 |
|------|--------:|------:|---:|---:|
| Logistic Regression | 0.83 | 0.48 | 0.58 | 0.65 |
| Random Forest | 0.86 | 0.52 | 0.61 | 0.68 |
| **XGBoost** | **0.89** | **0.57** | **0.64** | **0.72** |

> Include confusion matrix at the selected operating threshold.

---

## ğŸ§‘â€ğŸ’» Author
**Mohammad Ziaee** â€” Computer Engineer | AI & Data Science  
ğŸ“§ moha2012zia@gmail.com  
ğŸ”— https://github.com/ziaee-mohammad

---

## ğŸ· Tags
```
data-science
machine-learning
classification
churn-prediction
customer-analytics
tabular-data
model-evaluation
feature-engineering
python
jupyter-notebook
``

---

## ğŸ“œ License
MIT â€” free to use and adapt with attribution.
